{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f287efc-c955-4a52-923c-a4c900ceb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "import os\n",
    "import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ecad40-9216-4698-8532-b6b992765b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect snowflake to python\n",
    "conn = snowflake.connector.connect(\n",
    "    user = 'CHAITANYA35',\n",
    "    password = '',\n",
    "    account = '',\n",
    "    warehouse = 'COMPUTE_WH',\n",
    "    database = 'ISM',\n",
    "    schema = 'DATA'\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c64fb64-10de-4dd4-b7d7-efba045dc3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(stock_symbol):\n",
    "    stock_name = stock_symbol.upper() + \".NS\"\n",
    "    try:\n",
    "        stock_data = yf.Ticker(stock_name)\n",
    "        all_data = stock_data.history(period=\"max\", auto_adjust=True)\n",
    "\n",
    "        if all_data.empty:\n",
    "            print(f\"No Data found fot {stock_symbol}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        all_data.reset_index(inplace=True)\n",
    "        all_data = all_data.rename(columns={\n",
    "            'Date': 'price_date',\n",
    "            'Open': 'open_price',\n",
    "            'High': 'high_price',\n",
    "            'Low': 'low_price',\n",
    "            'Close': 'close_price',\n",
    "            'Volume': 'volume'\n",
    "        })\n",
    "\n",
    "        # add stock_symbol column as well.\n",
    "        all_data['stock_symbol'] = stock_symbol.upper()\n",
    "        all_data['price_date'] = pd.to_datetime(all_data['price_date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        # reorder all columns.\n",
    "        all_data = all_data[['stock_symbol', 'price_date', 'open_price', 'high_price', 'low_price', 'close_price', 'volume']]\n",
    "\n",
    "        return all_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {stock_name}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d4dfec-979f-43c4-9716-706361607776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_upload(stock_symbol, group):\n",
    "    try:\n",
    "        folder = \"temp_parquet_files_parallel_load\"\n",
    "        os.makedirs(folder,exist_ok=True)\n",
    "\n",
    "        file_name = os.path.join(folder,f\"{stock_symbol}.parquet\")\n",
    "        group.to_parquet(file_name, engine='pyarrow', index=False)\n",
    "\n",
    "        absolute_path = os.path.abspath(file_name)\n",
    "        basename = os.path.basename(file_name)\n",
    "        \n",
    "        cursor.execute(f\"PUT file://{absolute_path} @stage_stock_prices_parallel_load OVERWRITE=True\")\n",
    "        cursor.execute(f\"\"\"\n",
    "            COPY INTO stock_prices_parallel_load\n",
    "            FROM @stage_stock_prices_parallel_load/{basename}\n",
    "            FILE_FORMAT = (TYPE = 'PARQUET')\n",
    "            MATCH_BY_COLUMN_NAME=CASE_INSENSITIVE\n",
    "            \"\"\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {stock_symbol}: {e}\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99353a70-61ad-48c6-9455-598e63d36c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_start(process_name):\n",
    "    start_time = datetime.datetime.now()\n",
    "    cursor.execute(\"\"\"\n",
    "    INSERT INTO DATA_LOAD_LOG (PROCESS_NAME, START_TIME, STATUS)\n",
    "    VALUES (%s, %s, %s)\n",
    "    \"\"\", (process_name, start_time, 'Running'))\n",
    "\n",
    "def log_end(status, message = ''):\n",
    "    end_time = datetime.datetime.now()\n",
    "    cursor.execute(\"\"\"\n",
    "    UPDATE DATA_LOAD_LOG\n",
    "    SET END_TIME = %s, STATUS = %s, MESSAGE = %s\n",
    "    WHERE ID IN (SELECT ID FROM DATA_LOAD_LOG WHERE STATUS='Running')\n",
    "    \"\"\", (end_time, status,message))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c40382-aecf-4b2f-a300-6d22f5f745e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_symbol    2279957\n",
      "price_date      2279957\n",
      "open_price      2279956\n",
      "high_price      2279956\n",
      "low_price       2279956\n",
      "close_price     2279956\n",
      "volume          2279957\n",
      "dtype: int64\n",
      "Data Load Failed\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    process_name = \"Stock_Data_Parallel_Load\"\n",
    "\n",
    "    try:   \n",
    "        log_start(process_name)\n",
    "        cursor.execute(\"select stock_symbol from stock_symbol limit 5\")\n",
    "        stock_list = [row[0] for row in cursor.fetchall()]\n",
    "    \n",
    "        df_all_stocks_data = pd.DataFrame()    \n",
    "        for stock in stock_list:\n",
    "            df = get_stock_data(stock)\n",
    "            if not df.empty:\n",
    "                df_all_stocks_data = pd.concat([df_all_stocks_data,df], ignore_index=True) \n",
    "    \n",
    "        # Check dataframe information\n",
    "        print(df_all_stocks_data.count()) \n",
    "    \n",
    "        # Truncate Table First.\n",
    "        cursor.execute(\"Truncate table stock_prices_parallel_load\")\n",
    "    \n",
    "        # Split by stock symbol\n",
    "        stock_groups = [(stock, group) for stock, group in df_all_stocks_data.groupby('stock_symbol')]\n",
    "    \n",
    "        cursor.execute(\"CREATE STAGE IF NOT EXISTS stage_stock_prices_parallel_load\")\n",
    "    \n",
    "        # Parallel Processing\n",
    "        with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "            futures = [executor.submit(save_and_upload, stock, group) for stock, group in stock_groups]    \n",
    "        \n",
    "        log_end('Success', 'Data Load Sucessfull')\n",
    "        Print('Data Loaded Sucessfully')\n",
    "        conn.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        log_end('Failed', 'Data Load Failed')\n",
    "        print('Data Load Failed')\n",
    "        conn.commit()\n",
    "\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcafd20-b927-4004-8fc3-3df0a7e26ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570969b6-b011-4469-94bb-e9c3b57a681a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
